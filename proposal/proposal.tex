\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with`a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{Senior Project Proposal: Vocal Programming Language}
\author{Alex MacLean}

\begin{document}
\maketitle



\section{Background and Related Work}

People have been coding by voice for at least 10 years now. Current systems, such as VoiceCode, Talon, Caster, and Aenea \cite{nature} 
add a layer between an existing voice to text system like Dragon and an existing code editor like Vim, Visual Studio, or DrRacket. This layer looks for command words like ``kebab'', which causes following words to be formatted kebab-style, or made up words like ``lape'' for a pair of parentheses (Maybe something like ``huh'' for the `?' symbol). There are also words or phrases that trigger navigation hotkeys. A system like this has the advantage of working reasonably well for any language, though as with an IDE special commands might be added to allow quickly adding boiler-plate. 

One of the major challenges of existing systems seems to be that there is a very steep and long learning curve. One speaker said he had over 2,000 voice commands, and while its likely a user could still be productive with far fewer, even hundreds is a lot to learn. As evidence of the limits of existing technology, they seems to be designed for and used almost exclusively by people who have lost the ability to use a keyboard. While it's great that these people are being served, its telling that anyone who has a choice is sticking with a keyboard instead of spending months to learn a voice to code system. Another limitation seems to be that existing systems often mishear their users, especially when they are not in a silent space with an expensive microphone.

\section{Overall Goals}

For this project I'm interested in addressing the voice code problem in the speech to text system and the programming language as opposed to just adding a layer between them. Speech to text systems could be specialized for programming so that they resolve noisy input in a way that makes sense given the context of the program, as opposed to natural English language. For example, in a normal context the utterance ``wī'' would likely mean ``why'', however in programming ``y'' seems like a more appropriate choice (especially if that id is in scope or it is preceded by ``x''). Existing systems get around this by using a phonetic alphabet, so a command word like ``yap'' means ``y''. If the model used by speech to text system were modified, it might be possible to use the normal alphabet and reduce the barrier to entry. A better model would also reduce the error rate, especially in more noisy environments.

On the language design side of the problem, I'm interested in writing a language with voice in mind that can then be compiled into another high level language. Developing this language would require augmenting normal compilation with natural language processing and program synthesis. The surface syntaxes of existing languages are designed to be easy to type and looks good on a screen, but those are not the same concerns when designing a language for voice. A language for vocal programming might have new forms to specify programs in a less line-by-line manner, allow developers some leeway with regard to specific wording, or use a much less symbol heavy surface syntax.

In short, I want to build a system that can be told something like ``define a function factorial that takes an int n if n equals zero return one otherwise return n times factorial of n minus one.'' and produces a program in a language like Racket, JavaScript, or Python.

\section{Tentative Sprint Schedule}

% A tentative “sprint”-level proposed schedule. This should include tentative goals for each two-week period in both the first and second halves of the project. In other words, ten sprint goals. These goals should be concrete and testable, but they don’t have to come true. Goals like “research techniques for sound compression” don’t actually correspond to any deliverable, and have the habit of more or less evaporating. “Implement the Fast Fourier Transform”, on the other hand, is something we can probably work with.


\subsection{Winter Quarter}
\begin{enumerate}
    \item Write Project Proposal and find and read 5 papers related to voice programming, language design, and program synthesis from a description.
    \item Find an open source voice to text library, tweak the language model in some way, and build and run the code.
    \item Design and train a language model for writing code in specific.
    \item Integrate the new model into the open source library and get it running.
    \item Gather accuracy metrics for the new and original systems, experiment with tweaking the model to improve accuracy.
\end{enumerate}
\subsection{Spring Quarter}
\begin{enumerate}
    \item Write an EBNF and a parser for a simple version of the voice programming language.
    \item Get a compiler working from the voice language to another high level language like python, racket, or Java.
    \item Integrate the speech to text system and the compiler into some program that writes the code to the screen as it is spoken.
    \item Experiment with using large natural language models and macros in the language to make vocal programming better.
    \item Upload a cleaned-up version of the code to GitHub, make a simple website with an easy-to-download version of the system. Write the final report.
\end{enumerate}

\nocite{*}
\bibliographystyle{ieeetr}
\bibliography{proposal}

\end{document}